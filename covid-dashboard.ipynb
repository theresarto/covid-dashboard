{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf8999cb-8efc-41f4-9de3-79f76f6ee7df",
   "metadata": {},
   "source": [
    "# DIY Covid Tracking Dashboard # \n",
    "ECS780P Computer Programming Coursework \n",
    "by **Theresa Rivera To**, 240419758, MSc Computing and Information Systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc76ba-556a-402a-a6ab-fe486f22485f",
   "metadata": {},
   "source": [
    "### Purpose  \n",
    "Track and visualise COVID-19 cases across London boroughs using an interactive dashboard. This helps you dive into borough-specific trends or check aggregated data.\n",
    "\n",
    "### Features  \n",
    "- Easy dropdowns to filter by borough, year, and month.  \n",
    "- Automatic data fetching and plotting from the API.  \n",
    "- Live updates and progress tracking during data fetches.\n",
    "- Save button functionality.\n",
    "\n",
    "---\n",
    "\n",
    "### Essential Information  \n",
    "#### File Structure  \n",
    "- **Notebook**: `covid-dashboard.ipynb`  \n",
    "- **Scripts**:  \n",
    "  - `api_wrapper.py`: Wraps API-specific logic for reusability.  \n",
    "- **Data Folder**:  \n",
    "  - `combined_df.json`: Saves fetched data locally.\n",
    "- **Classes**:\n",
    "  - `class Fetcher`: Handles API calls and data fetching. Also modularises saving data.\n",
    "\n",
    "---\n",
    "\n",
    "### How to Use  \n",
    "1. Run the notebook and load the saved data to visualise immediately.  \n",
    "2. If the data is outdated, click the \"Fetch Data\" button to retrieve the latest information.  \n",
    "3. Use the dropdowns to filter data by borough, year, or month.  \n",
    "4. View progress in the notebook while fetching.\n",
    "5. Save data after fetching to get the latest JSON file.  \n",
    "\n",
    "#### Note  \n",
    "Ensure the required Python libraries are installed. A `requirements.txt` file is provided for convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52daa7f2-7723-4d90-b312-c8f8c2801e4c",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a00371-4259-40cf-9893-0bed5877be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output, FileLink\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Output, interact, widgets, Button, HBox\n",
    "import time\n",
    "import gzip\n",
    "\n",
    "import json\n",
    "\n",
    "from api_wrapper import APIwrapper\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6c0416-f55c-4e53-88c0-8e7cc6537d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------- MODULARISE WITH WRAPPER ----------------------------------- #\n",
    "\n",
    "# TODO function outside API class --> Turns data into a Pandas DataFrame\n",
    "def fetch_data_with_wrapper(geography_type, borough, metric_name):\n",
    "    \"\"\"\n",
    "    Fetch all pages of data for a given metric using the APIwrapper.\n",
    "    Returns a Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    structure = {\n",
    "        \"theme\": \"infectious_disease\",\n",
    "        \"sub_theme\": \"respiratory\",\n",
    "        \"topic\": \"COVID-19\",\n",
    "        \"geography_type\": geography_type,\n",
    "        \"geography\": borough,\n",
    "        \"metric\": metric_name,\n",
    "    }\n",
    "\n",
    "    api = APIwrapper(**structure)\n",
    "\n",
    "    try:\n",
    "        data = api.get_all_pages()\n",
    "        return pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for metric {metric_name}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eab8c23-fddf-4b21-b47c-9f965f136417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------- SET UP FETCHER ----------------------------------- #\n",
    "\n",
    "class Fetcher:\n",
    "    \"\"\"\n",
    "    High-level class for fetching and combining data for multiple boroughs. Uses the fetch_data_with_wrapper that uses APIwrapper provided. (ツ)_/¯ \n",
    "    \"\"\"\n",
    "\n",
    "    # TODO 1: initialise this fetcher. When you initialise, this will require you to add your params\n",
    "    def __init__(self, geography_type, metric_name):\n",
    "        self.geography_type = geography_type\n",
    "        self.metric_name = metric_name\n",
    "        self.borough_data = {}\n",
    "        self.output = Output()  # Add an Output widget\n",
    "\n",
    "    def fetch_borough_data(self, borough):\n",
    "        \"\"\"\n",
    "        Fetch data for a single borough and store it in the borough_data dictionary.\n",
    "        \"\"\"\n",
    "        with self.output:\n",
    "            borough_name = borough.replace(\"%20\", \" \")\n",
    "            print(f\"Fetching data for {borough_name}...\")\n",
    "            try:\n",
    "                # TODO 2: Use the outside function for fetchin (comes from APIwrapper module)\n",
    "                data = fetch_data_with_wrapper(self.geography_type, borough, self.metric_name)\n",
    "\n",
    "                if not data.empty:\n",
    "                    data[\"borough\"] = borough_name\n",
    "                    self.borough_data[borough] = data\n",
    "                    print(f\"✓ {borough_name} - {len(data)} records fetched.\")\n",
    "                else:\n",
    "                    print(f\"✗ {borough_name} - No data available.\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error fetching data for {borough_name}: {e}\")\n",
    "\n",
    "    def fetch_all_boroughs(self, borough_list):\n",
    "        \"\"\"\n",
    "        Fetch data for all boroughs in the given list and combine into a single DataFrame.\n",
    "        \"\"\"\n",
    "        with self.output:\n",
    "            # TODO 3: The borough list is in notebook. Iterate through each so you can get all teh data\n",
    "            for borough in borough_list:\n",
    "                self.fetch_borough_data(borough)  # Fetch data for each borough\n",
    "            print() \n",
    "\n",
    "            # TODO 4: Bec a lot of boroughs, we'll combine them into one DF\n",
    "            if self.borough_data:\n",
    "                combined_df = pd.concat(self.borough_data.values(), ignore_index=True)\n",
    "                combined_df[\"date\"] = pd.to_datetime(combined_df[\"date\"])  # Ensure date column is datetime\n",
    "                print(f\"SUCCESS! Combined data contains {len(combined_df)} rows across {len(self.borough_data)} boroughs.\")\n",
    "                return combined_df\n",
    "            else:\n",
    "                print(\"No data was fetched for any borough.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "    def display_output(self):\n",
    "        \"\"\"\n",
    "        Display the Output widget for Voila compatibility.\n",
    "        \"\"\"\n",
    "        display(self.output)\n",
    "\n",
    "    # TODO 5: Save this into a JSON file. Call this every time BUTTON in next module wants to reload data\n",
    "    def save_and_download_gzipped_file(self, dataframe, filename=\"combined_df.json.gz\"):\n",
    "        \"\"\"\n",
    "        Save the DataFrame as a gzipped JSON file and generate a download link.\n",
    "        \"\"\"\n",
    "        print(\"Saving file as gzipped JSON...\")\n",
    "        try:\n",
    "            if not dataframe.empty:\n",
    "                # Save the DataFrame to a gzipped JSON file\n",
    "                with gzip.open(filename, \"wt\") as f:\n",
    "                    dataframe.to_json(f, orient=\"records\", indent=4)\n",
    "                print(f\"Data successfully saved to '{filename}'\")\n",
    "                \n",
    "                # Generate and display a download link\n",
    "                display(FileLink(filename))\n",
    "            else:\n",
    "                print(\"No data available to save.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516f4be4-ea9c-4db9-93ac-e1fb702676b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------- TIME FOR ACTION ----------------------------------- #\n",
    "\n",
    "# Identify global parameters we're feeding\n",
    "geography_type = \"Lower%20Tier%20Local%20Authority\"\n",
    "metrics = \"COVID-19_cases_casesByDay\"\n",
    "\n",
    "london_boroughs = [\"Barking%20and%20Dagenham\", \"Barnet\", \"Bexley\", \"Brent\", \"Bromley\", \"Camden\", \"Croydon\", \"Ealing\",\n",
    "                   \"Enfield\", \"Greenwich\", \"Hackney%20and%20City%20of%20London\", \"Hammersmith%20and%20Fulham\", \"Haringey\", \"Harrow\", \"Havering\",\n",
    "                   \"Hillingdon\", \"Hounslow\", \"Islington\", \"Kensington%20and%20Chelsea\", \"Kingston%20upon%20Thames\",\n",
    "                   \"Lambeth\", \"Lewisham\", \"Merton\", \"Newham\", \"Redbridge\", \"Richmond%20upon%20Thames\", \"Southwark\",\n",
    "                   \"Sutton\", \"Tower%20Hamlets\", \"Waltham%20Forest\", \"Wandsworth\", \"Westminster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c370ef2d-e3a9-49e8-9a62-e876b08e9896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Fetcher module created for London Boroughs\n",
    "fetcher = Fetcher(geography_type, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6436d83e-af11-4c40-96eb-0cfc21e585bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fetcher.save_combined_data(london_boroughs) is commented out once the data is saved the first time as offline data. There is a save button at the bottom of the widget which also allows you to save the latest data.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine borough data into single JSON and SAVE it (filepath already determined in function)\n",
    "\"\"\"fetcher.save_combined_data(london_boroughs) is commented out once the data is saved the first time as offline data. There is a save button at the bottom of the widget which also allows you to save the latest data.\"\"\"\n",
    "# combined_df = fetcher.fetch_all_boroughs(london_boroughs)\n",
    "#fetcher.save_combined_data(combined_df, \"combined_df.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c52c5da-006e-4c5d-90aa-5a9d7c4b1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output widget for rendering plots\n",
    "output_widget = Output()\n",
    "\n",
    "# ----------------------------------- PLOTTING ----------------------------------- #\n",
    "\n",
    "# TODO: Set up the plot\n",
    "def plot_cases(cases_df, year=None, month=None, boroughs=None):\n",
    "    \"\"\"\n",
    "    Plot cases for London boroughs with optional filtering by year, month, and boroughs.\n",
    "    \"\"\"\n",
    "\n",
    "    # # TODO debug!!\n",
    "    # print(\"Initial DataFrame:\")\n",
    "    # print(cases_df.head())  # Debug: Print the DataFrame before filtering\n",
    "\n",
    "    if cases_df is None or cases_df.empty:\n",
    "        with output_widget:\n",
    "            output_widget.clear_output(wait=True)\n",
    "            print(\"Cannot plot. DataFrame is missing or empty.\")\n",
    "        return\n",
    "\n",
    "    # Filter data by year\n",
    "    if year and year != \"All\":\n",
    "        cases_df = cases_df[cases_df[\"date\"].dt.year == int(year)]\n",
    "\n",
    "    # Filter data by month\n",
    "    if month and month != \"All\":\n",
    "        cases_df = cases_df[cases_df[\"date\"].dt.month == int(month)]\n",
    "\n",
    "    # TODO: DEBUG BOROUGHS\n",
    "    # Filter data by boroughs\n",
    "    if boroughs and \"All\" not in boroughs:\n",
    "        # print(\"Filtering for boroughs:\", boroughs)  # Debug\n",
    "        cases_df = cases_df[cases_df[\"borough\"].isin(boroughs)]\n",
    "    # Sort boroughs alphabetically before plotting\n",
    "    sorted_boroughs = sorted(cases_df[\"borough\"].unique())\n",
    "\n",
    "    # print(\"Filtered DataFrame after applying boroughs, year, and month:\")\n",
    "    # print(cases_df.head())  # Debug\n",
    "\n",
    "    # Plot the filtered data\n",
    "    with output_widget:\n",
    "        output_widget.clear_output(wait=True)\n",
    "        plt.figure(figsize=(16, 7))\n",
    "\n",
    "        for borough in sorted_boroughs:\n",
    "            borough_data = cases_df[cases_df[\"borough\"] == borough]\n",
    "            plt.plot(borough_data[\"date\"], borough_data[\"metric_value\"], label=borough)\n",
    "\n",
    "        plt.title(\"COVID-19 Cases in London Boroughs per 100,000 People\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Number of Cases\")\n",
    "        plt.legend(loc=\"upper left\", bbox_to_anchor=(1.05, 1), fontsize=\"small\", title=\"Boroughs\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# --------------------------------- HELPER: LOAD JSON -------------------------------- #\n",
    "\n",
    "# TODO: Load the initial JSON\n",
    "def load_initial_data(filepath=\"combined_df.json.gz\"):\n",
    "    \"\"\"\n",
    "    Load the initial data from the JSON file for offline access.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with gzip.open(filepath, \"rt\") as f:\n",
    "            json_data = json.load(f)\n",
    "        print(\"Loaded initial data successfully.\")\n",
    "        df = pd.DataFrame(json_data)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], unit='ms')\n",
    "        df = df.sort_values(by=\"date\").reset_index(drop=True)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filepath} not found. Please fetch data using the 'Fetch Data' button.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ------------------------------ CREATE WIDGET ------------------------------ #\n",
    "\n",
    "def update_cases_plot(cases_df, year, month, boroughs):\n",
    "    \"\"\"\n",
    "    Update the plot dynamically based on widget values.\n",
    "    We will be calling this in create_widgets(df) below!\n",
    "    \"\"\"\n",
    "    # print(f\"Year: {year}, Month: {month}, Boroughs: {boroughs}\")  # Debug print\n",
    "    plot_cases(cases_df, year=year, month=month, boroughs=boroughs)\n",
    "\n",
    "\n",
    "def create_widgets(cases_df):\n",
    "    \"\"\"\n",
    "    Create interactive widgets and display them.\n",
    "    \"\"\"\n",
    "    # TODO Debugging: Ensure DataFrame is passed correctly\n",
    "    # print(\"Initial DataFrame passed to create_widgets:\")\n",
    "    # print(cases_df.head())\n",
    "    # print(\"Unique boroughs in DataFrame:\", cases_df[\"borough\"].unique())  # Debug\n",
    "\n",
    "    # TODO: Detail the dropdown widgets\n",
    "    year_dropdown = widgets.Dropdown(\n",
    "        options=[\"All\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"],\n",
    "        value=\"All\",\n",
    "        description=\"Year:\"\n",
    "    )\n",
    "\n",
    "    month_dropdown = widgets.Dropdown(\n",
    "        options=[\"All\"] + [f\"{i:02d}\" for i in range(1, 13)],\n",
    "        value=\"All\",\n",
    "        description=\"Month:\"\n",
    "    )\n",
    "\n",
    "    borough_dropdown = widgets.SelectMultiple(\n",
    "        options=[\"All\"] + sorted(cases_df[\"borough\"].unique()),\n",
    "        value=(\"All\",),\n",
    "        description=\"Borough(s):\",\n",
    "        layout=widgets.Layout(width=\"50%\")\n",
    "    )\n",
    "\n",
    "    fetch_button = Button(\n",
    "        description=\"Fetch New Data\",\n",
    "        button_style='primary',\n",
    "        tooltip=\"Fetch latest data from the API\",\n",
    "        icon=\"refresh\"\n",
    "    )\n",
    "\n",
    "    save_button = Button(\n",
    "        description=\"Save All Data\",\n",
    "        button_style=\"success\",\n",
    "        tooltip=\"Save the current data to JSON file\",\n",
    "        icon=\"save\"\n",
    "    )\n",
    "\n",
    "    # FETCH BUTTON SETUP\n",
    "    def fetch_button_callback(button):\n",
    "        global cases_df, london_boroughs, geography_type, metrics\n",
    "        print(\"Fetching data...\")\n",
    "\n",
    "        # TODO: Reload the output_widget with new data\n",
    "        with output_widget:  # Use the global `output_widget` to show progress to solve progress issue\n",
    "            clear_output(wait=True)\n",
    "            print(\"FETCH REQUESTED. Please wait as it may take a while.\")\n",
    "            fetcher.display_output()  # Display Fetcher's Output widget in the notebook. Have to do this because can't see progress\n",
    "            cases_df = fetcher.fetch_all_boroughs(london_boroughs)  # Reuse fetcher to fetch all borough data\n",
    "\n",
    "            if not cases_df.empty:\n",
    "                print(\"\\nData fetching complete. Click on your selected filter to plot.\")\n",
    "                # TODO: Get plot to load agin after fetching or else will look silly\n",
    "                print(\"Graph will now reload in \", end=\"\")\n",
    "                for i in range(3, 0, -1):\n",
    "                    print(f\"{i}\", end=\" \")\n",
    "                    time.sleep(1)\n",
    "                print(\"🚀\")\n",
    "                time.sleep(1)\n",
    "                update_cases_plot(cases_df, year=\"All\", month=\"All\", boroughs=(\"All\",))  # Plot fetched data\n",
    "            else:\n",
    "                print(\"\\nNo data could be fetched. Please try again.\")\n",
    "\n",
    "    # TODO: SAVE BUTTON SETUP\n",
    "    def save_button_callback(button):\n",
    "        global cases_df\n",
    "        if cases_df is not None and not cases_df.empty:\n",
    "            with output_widget:  # Redirect output to the output_widget or else goes to log console\n",
    "                clear_output(wait=True)\n",
    "                fetcher.save_and_download_gzipped_file(cases_df, filename=\"combined_df.json.gz\")\n",
    "                print(\"A download link has been generated. Please download within 10 seconds.\")\n",
    "                print(\"Graph will reload in:\")\n",
    "                for i in range(10, 1, -1):\n",
    "                    print(f\"{i}\", end=\", \")\n",
    "                    time.sleep(1)\n",
    "                print(\"🚀\")\n",
    "                time.sleep(1)\n",
    "                update_cases_plot(cases_df, year=\"All\", month=\"All\", boroughs=(\"All\",))  # Plot fetched data\n",
    "        else:\n",
    "            print(\"No data available to save. Please fetch data first.\")\n",
    "\n",
    "    \n",
    "    # TODO: Combines everything above into a click\n",
    "    fetch_button.on_click(fetch_button_callback)\n",
    "    save_button.on_click(save_button_callback)\n",
    "\n",
    "    button_box = HBox([fetch_button, save_button])\n",
    "\n",
    "    \n",
    "    # TODO: Create interactive widgets for plotting. Failed to work w/o interact :(\n",
    "    interact(lambda year, month, boroughs: update_cases_plot(cases_df, year, month, boroughs),\n",
    "             year=year_dropdown, month=month_dropdown, boroughs=borough_dropdown)\n",
    "    \n",
    "    display(button_box)\n",
    "    display(output_widget)\n",
    "    \n",
    "\n",
    "\n",
    "# ------------------------------------ MAIN ------------------------------------ #\n",
    "\n",
    "# Prevent automatic execution on import (IDE only)\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load initial data\n",
    "#     cases_df = load_initial_data()\n",
    "\n",
    "#     # Show initial plot if data exists\n",
    "#     if cases_df is not None:\n",
    "#         plot_cases(cases_df)\n",
    "\n",
    "#     # Create widgets\n",
    "#     create_widgets(cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f95e25-7e6f-418c-b95d-277c5fd1b3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded initial data successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load initial data from JSON\n",
    "filepath = \"combined_df.json.gz\"\n",
    "cases_df = load_initial_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be03924-a33b-45df-9b1f-5a3944b9259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if cases has content\n",
    "# cases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa79d6cb-6803-4d5d-b8e9-444a1f56e5be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d60d71f42d745d2be0d8286d96c101a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Year:', options=('All', '2020', '2021', '2022', '2023', '2024'), v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d913b71ca7d4be9977ad97199c23f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Fetch New Data', icon='refresh', style=ButtonStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ea28e6960a4534a806a9e5baf1999f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Manually call the widget to load it\n",
    "if cases_df is not None:\n",
    "    create_widgets(cases_df)\n",
    "else:\n",
    "    print(\"No data loaded. Fetch new data using the Fetch button.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b47f7-fb18-4651-af6e-4ff7bbc18c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a707150-e188-408d-abe8-c0eddb0a815d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
